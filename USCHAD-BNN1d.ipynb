{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics.classification import accuracy_score, recall_score, f1_score\n",
    "import scipy.stats as st\n",
    "import sys\n",
    "import os\n",
    "sys.path.append('../quantnn-keras/layers/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.models import Sequential\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.losses import squared_hinge\n",
    "from keras.layers import Flatten, Dense, Activation, BatchNormalization, Conv1D\n",
    "\n",
    "from keras.models import Sequential, Model\n",
    "import numpy as np\n",
    "\n",
    "from binary_layers import BinaryConv2D, BinaryConv1D\n",
    "from binary_ops import binary_tanh as binary_tanh_op\n",
    "from keras.regularizers import l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_input_file = 'data/LOSO/USCHAD.npz'\n",
    "\n",
    "tmp = np.load(data_input_file)\n",
    "X = tmp['X']\n",
    "y = tmp['y']\n",
    "folds = tmp['folds']\n",
    "\n",
    "n_class = y.shape[1]\n",
    "\n",
    "avg_acc = []\n",
    "avg_recall = []\n",
    "avg_f1 = []\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "print('ConvNet Template 2017 {}'.format(data_input_file))\n",
    "\n",
    "for i in range(0, len(folds)):\n",
    "    train_idx = folds[i][0]\n",
    "    test_idx = folds[i][1]\n",
    "\n",
    "    X_train, y_train = X[train_idx], y[train_idx]\n",
    "    X_test, y_test = X[test_idx], y[test_idx]\n",
    "    X_train = X_train.squeeze()\n",
    "    X_test = X_test.squeeze()\n",
    "    y_train = to_categorical(y_train)\n",
    "    y_test = to_categorical(y_test)\n",
    "    \n",
    "    # Create Model\n",
    "    model = Sequential()\n",
    "\n",
    "    _momentum = 0.1\n",
    "    _epsilon = 0.001\n",
    "    \n",
    "    model.add(\n",
    "        BinaryConv1D(\n",
    "            kernel_size=30,\n",
    "            filters=64,\n",
    "            padding='same',\n",
    "            input_shape=(250,23),\n",
    "            kernel_lr_multiplier=10,use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=_momentum, epsilon=_epsilon))\n",
    "    model.add(Activation(binary_tanh_op))\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        BinaryConv1D(\n",
    "            kernel_size=30, filters=128, padding='same',\n",
    "            kernel_lr_multiplier=10,use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=_momentum, epsilon=_epsilon))\n",
    "    model.add(Activation(binary_tanh_op))\n",
    "\n",
    "\n",
    "    model.add(\n",
    "        BinaryConv1D(\n",
    "            kernel_size=30, filters=256, padding='same',\n",
    "            kernel_lr_multiplier=10,use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=_momentum, epsilon=_epsilon))\n",
    "    model.add(Activation(binary_tanh_op))\n",
    "\n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(12, use_bias=False))\n",
    "    model.add(BatchNormalization(momentum=_momentum, epsilon=_epsilon))\n",
    "\n",
    "    # Train\n",
    "    adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "    model.compile(loss=squared_hinge, optimizer=adam, metrics=['accuracy'])\n",
    "    #model.summary()\n",
    "\n",
    "    model.fit(\n",
    "        X_train, y_train, batch_size=50, epochs=100, validation_data=(X_test,y_test), verbose=0 )\n",
    "    print (model.evaluate(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Template 2017 data/LOSO/USCHAD.npz\n",
      "(8931, 500, 6) (893, 500, 6)\n",
      "(8931, 12) (893, 12)\n"
     ]
    }
   ],
   "source": [
    "data_input_file = 'data/LOSO/USCHAD.npz'\n",
    "\n",
    "tmp = np.load(data_input_file)\n",
    "X = tmp['X']\n",
    "y = tmp['y']\n",
    "folds = tmp['folds']\n",
    "\n",
    "n_class = y.shape[1]\n",
    "\n",
    "avg_acc = []\n",
    "avg_recall = []\n",
    "avg_f1 = []\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "print('ConvNet Template 2017 {}'.format(data_input_file))\n",
    "\n",
    "i = 0\n",
    "train_idx = folds[i][0]\n",
    "test_idx = folds[i][1]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "X_train = X_train.squeeze()\n",
    "X_test = X_test.squeeze()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "print (X_train.shape, X_test.shape)\n",
    "print (y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 2) 14\n"
     ]
    }
   ],
   "source": [
    "print (folds.shape, len(folds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Template 2017 data/LOSO/USCHAD.npz\n",
      "WARNING:tensorflow:From /home/ankdesh/virtualenvs/bnns/lib/python3.5/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "binary_conv1d_1 (BinaryConv1 (None, 500, 64)           3840      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "binary_conv1d_2 (BinaryConv1 (None, 500, 128)          81920     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "binary_conv1d_3 (BinaryConv1 (None, 500, 128)          163840    \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 500, 128)          512       \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 500, 128)          0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 64000)             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 12)                768000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 12)                48        \n",
      "=================================================================\n",
      "Total params: 1,018,928\n",
      "Trainable params: 1,018,264\n",
      "Non-trainable params: 664\n",
      "_________________________________________________________________\n",
      "WARNING:tensorflow:From /home/ankdesh/virtualenvs/bnns/lib/python3.5/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 8931 samples, validate on 893 samples\n",
      "Epoch 1/100\n",
      "8931/8931 [==============================] - 80s 9ms/step - loss: 0.9528 - acc: 0.3137 - val_loss: 0.9268 - val_acc: 0.4031\n",
      "Epoch 2/100\n",
      "8931/8931 [==============================] - 79s 9ms/step - loss: 0.9250 - acc: 0.4538 - val_loss: 0.9286 - val_acc: 0.3012\n",
      "Epoch 3/100\n",
      "8931/8931 [==============================] - 78s 9ms/step - loss: 0.9204 - acc: 0.5116 - val_loss: 0.9262 - val_acc: 0.4233\n",
      "Epoch 4/100\n",
      "8931/8931 [==============================] - 82s 9ms/step - loss: 0.9193 - acc: 0.5222 - val_loss: 0.9229 - val_acc: 0.3919\n",
      "Epoch 5/100\n",
      "8931/8931 [==============================] - 79s 9ms/step - loss: 0.9184 - acc: 0.5361 - val_loss: 0.9215 - val_acc: 0.3516\n",
      "Epoch 6/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9181 - acc: 0.5557 - val_loss: 0.9220 - val_acc: 0.4031\n",
      "Epoch 7/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9177 - acc: 0.5751 - val_loss: 0.9222 - val_acc: 0.4155\n",
      "Epoch 8/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9174 - acc: 0.5881 - val_loss: 0.9221 - val_acc: 0.4412\n",
      "Epoch 9/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9173 - acc: 0.6086 - val_loss: 0.9228 - val_acc: 0.4770\n",
      "Epoch 10/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9173 - acc: 0.6095 - val_loss: 0.9199 - val_acc: 0.4748\n",
      "Epoch 11/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9171 - acc: 0.6192 - val_loss: 0.9202 - val_acc: 0.4748\n",
      "Epoch 12/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9170 - acc: 0.6261 - val_loss: 0.9208 - val_acc: 0.5017\n",
      "Epoch 13/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9170 - acc: 0.6390 - val_loss: 0.9189 - val_acc: 0.4289\n",
      "Epoch 14/100\n",
      "8931/8931 [==============================] - 78s 9ms/step - loss: 0.9169 - acc: 0.6404 - val_loss: 0.9212 - val_acc: 0.5106\n",
      "Epoch 15/100\n",
      "8931/8931 [==============================] - 80s 9ms/step - loss: 0.9169 - acc: 0.6513 - val_loss: 0.9195 - val_acc: 0.4871\n",
      "Epoch 16/100\n",
      "8931/8931 [==============================] - 81s 9ms/step - loss: 0.9169 - acc: 0.6486 - val_loss: 0.9200 - val_acc: 0.5297\n",
      "Epoch 17/100\n",
      "8931/8931 [==============================] - 77s 9ms/step - loss: 0.9169 - acc: 0.6559 - val_loss: 0.9202 - val_acc: 0.4099\n",
      "Epoch 18/100\n",
      "8931/8931 [==============================] - 74s 8ms/step - loss: 0.9168 - acc: 0.6658 - val_loss: 0.9195 - val_acc: 0.4311\n",
      "Epoch 19/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9168 - acc: 0.6604 - val_loss: 0.9194 - val_acc: 0.3998\n",
      "Epoch 20/100\n",
      "8931/8931 [==============================] - 76s 9ms/step - loss: 0.9168 - acc: 0.6657 - val_loss: 0.9196 - val_acc: 0.4983\n",
      "Epoch 21/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9168 - acc: 0.6663 - val_loss: 0.9191 - val_acc: 0.4546\n",
      "Epoch 22/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9168 - acc: 0.6732 - val_loss: 0.9190 - val_acc: 0.5510\n",
      "Epoch 23/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9168 - acc: 0.6747 - val_loss: 0.9197 - val_acc: 0.4009\n",
      "Epoch 24/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9168 - acc: 0.6725 - val_loss: 0.9200 - val_acc: 0.5118\n",
      "Epoch 25/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.6898 - val_loss: 0.9194 - val_acc: 0.5084\n",
      "Epoch 26/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9168 - acc: 0.6830 - val_loss: 0.9179 - val_acc: 0.4569\n",
      "Epoch 27/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.6952 - val_loss: 0.9190 - val_acc: 0.4334\n",
      "Epoch 28/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.6869 - val_loss: 0.9190 - val_acc: 0.4927\n",
      "Epoch 29/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7019 - val_loss: 0.9192 - val_acc: 0.5106\n",
      "Epoch 30/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7023 - val_loss: 0.9189 - val_acc: 0.4490\n",
      "Epoch 31/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.6958 - val_loss: 0.9197 - val_acc: 0.4961\n",
      "Epoch 32/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7015 - val_loss: 0.9197 - val_acc: 0.5185\n",
      "Epoch 33/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.6982 - val_loss: 0.9186 - val_acc: 0.5364\n",
      "Epoch 34/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7035 - val_loss: 0.9198 - val_acc: 0.4311\n",
      "Epoch 35/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7115 - val_loss: 0.9194 - val_acc: 0.5095\n",
      "Epoch 36/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7078 - val_loss: 0.9196 - val_acc: 0.4804\n",
      "Epoch 37/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7131 - val_loss: 0.9190 - val_acc: 0.5039\n",
      "Epoch 38/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7168 - val_loss: 0.9181 - val_acc: 0.5353\n",
      "Epoch 39/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7120 - val_loss: 0.9188 - val_acc: 0.4782\n",
      "Epoch 40/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7186 - val_loss: 0.9199 - val_acc: 0.5386\n",
      "Epoch 41/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7177 - val_loss: 0.9178 - val_acc: 0.4558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7194 - val_loss: 0.9186 - val_acc: 0.4188\n",
      "Epoch 43/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7318 - val_loss: 0.9178 - val_acc: 0.5476\n",
      "Epoch 44/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7274 - val_loss: 0.9183 - val_acc: 0.5633\n",
      "Epoch 45/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7326 - val_loss: 0.9178 - val_acc: 0.5230\n",
      "Epoch 46/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7310 - val_loss: 0.9176 - val_acc: 0.5677\n",
      "Epoch 47/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7341 - val_loss: 0.9188 - val_acc: 0.4580\n",
      "Epoch 48/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7308 - val_loss: 0.9189 - val_acc: 0.4412\n",
      "Epoch 49/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7323 - val_loss: 0.9180 - val_acc: 0.5442\n",
      "Epoch 50/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7295 - val_loss: 0.9182 - val_acc: 0.5431\n",
      "Epoch 51/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7238 - val_loss: 0.9185 - val_acc: 0.5532\n",
      "Epoch 52/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7318 - val_loss: 0.9182 - val_acc: 0.5420\n",
      "Epoch 53/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7321 - val_loss: 0.9189 - val_acc: 0.5330\n",
      "Epoch 54/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7294 - val_loss: 0.9182 - val_acc: 0.5767\n",
      "Epoch 55/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7344 - val_loss: 0.9187 - val_acc: 0.5286\n",
      "Epoch 56/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7308 - val_loss: 0.9180 - val_acc: 0.5409\n",
      "Epoch 57/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7379 - val_loss: 0.9180 - val_acc: 0.5375\n",
      "Epoch 58/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7400 - val_loss: 0.9182 - val_acc: 0.5398\n",
      "Epoch 59/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7262 - val_loss: 0.9182 - val_acc: 0.5554\n",
      "Epoch 60/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7349 - val_loss: 0.9185 - val_acc: 0.5420\n",
      "Epoch 61/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7411 - val_loss: 0.9179 - val_acc: 0.5442\n",
      "Epoch 62/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7373 - val_loss: 0.9177 - val_acc: 0.5297\n",
      "Epoch 63/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7490 - val_loss: 0.9180 - val_acc: 0.5431\n",
      "Epoch 64/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7441 - val_loss: 0.9184 - val_acc: 0.5498\n",
      "Epoch 65/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7443 - val_loss: 0.9180 - val_acc: 0.5129\n",
      "Epoch 66/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7453 - val_loss: 0.9180 - val_acc: 0.5622\n",
      "Epoch 67/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7428 - val_loss: 0.9181 - val_acc: 0.5644\n",
      "Epoch 68/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7412 - val_loss: 0.9184 - val_acc: 0.5577\n",
      "Epoch 69/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7382 - val_loss: 0.9186 - val_acc: 0.5442\n",
      "Epoch 70/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7352 - val_loss: 0.9180 - val_acc: 0.5554\n",
      "Epoch 71/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7344 - val_loss: 0.9189 - val_acc: 0.5823\n",
      "Epoch 72/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7446 - val_loss: 0.9186 - val_acc: 0.5319\n",
      "Epoch 73/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7412 - val_loss: 0.9186 - val_acc: 0.5263\n",
      "Epoch 74/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7409 - val_loss: 0.9179 - val_acc: 0.5330\n",
      "Epoch 75/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7439 - val_loss: 0.9180 - val_acc: 0.5319\n",
      "Epoch 76/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7427 - val_loss: 0.9179 - val_acc: 0.5778\n",
      "Epoch 77/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7462 - val_loss: 0.9178 - val_acc: 0.5610\n",
      "Epoch 78/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7428 - val_loss: 0.9176 - val_acc: 0.5577\n",
      "Epoch 79/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7425 - val_loss: 0.9181 - val_acc: 0.4703\n",
      "Epoch 80/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7439 - val_loss: 0.9179 - val_acc: 0.5969\n",
      "Epoch 81/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7421 - val_loss: 0.9177 - val_acc: 0.5498\n",
      "Epoch 82/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7441 - val_loss: 0.9177 - val_acc: 0.5879\n",
      "Epoch 83/100\n",
      "8931/8931 [==============================] - 76s 9ms/step - loss: 0.9167 - acc: 0.7489 - val_loss: 0.9175 - val_acc: 0.5733\n",
      "Epoch 84/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7415 - val_loss: 0.9178 - val_acc: 0.4692\n",
      "Epoch 85/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7464 - val_loss: 0.9175 - val_acc: 0.5935\n",
      "Epoch 86/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7433 - val_loss: 0.9174 - val_acc: 0.5756\n",
      "Epoch 87/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7473 - val_loss: 0.9175 - val_acc: 0.5644\n",
      "Epoch 88/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7508 - val_loss: 0.9172 - val_acc: 0.5543\n",
      "Epoch 89/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7447 - val_loss: 0.9176 - val_acc: 0.5633\n",
      "Epoch 90/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7439 - val_loss: 0.9172 - val_acc: 0.5868\n",
      "Epoch 91/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7519 - val_loss: 0.9177 - val_acc: 0.6047\n",
      "Epoch 92/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7533 - val_loss: 0.9177 - val_acc: 0.6025\n",
      "Epoch 93/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7392 - val_loss: 0.9181 - val_acc: 0.5823\n",
      "Epoch 94/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7499 - val_loss: 0.9175 - val_acc: 0.5778\n",
      "Epoch 95/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7427 - val_loss: 0.9179 - val_acc: 0.5476\n",
      "Epoch 96/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7455 - val_loss: 0.9178 - val_acc: 0.5801\n",
      "Epoch 97/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7452 - val_loss: 0.9178 - val_acc: 0.5935\n",
      "Epoch 98/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7396 - val_loss: 0.9182 - val_acc: 0.5812\n",
      "Epoch 99/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7403 - val_loss: 0.9173 - val_acc: 0.5106\n",
      "Epoch 100/100\n",
      "8931/8931 [==============================] - 75s 8ms/step - loss: 0.9167 - acc: 0.7528 - val_loss: 0.9176 - val_acc: 0.5722\n",
      "893/893 [==============================] - 2s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9176030285814976, 0.5722284435157947]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('ConvNet Template 2017 {}'.format(data_input_file))\n",
    "\n",
    "i = 0\n",
    "train_idx = folds[i][0]\n",
    "test_idx = folds[i][1]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "X_train = X_train.squeeze()\n",
    "X_test = X_test.squeeze()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    BinaryConv1D(\n",
    "        kernel_size=10,\n",
    "        filters=64,\n",
    "        padding='same',\n",
    "        input_shape=(500,6),\n",
    "        kernel_lr_multiplier=10,use_bias=False))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "model.add(Activation(binary_tanh_op))\n",
    "\n",
    "\n",
    "model.add(\n",
    "    BinaryConv1D(\n",
    "        kernel_size=10, filters=128, padding='same',\n",
    "        kernel_lr_multiplier=10,use_bias=False))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "model.add(Activation(binary_tanh_op))\n",
    "\n",
    "\n",
    "model.add(\n",
    "    BinaryConv1D(\n",
    "        kernel_size=10, filters=128, padding='same',\n",
    "        kernel_lr_multiplier=10,use_bias=False))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "model.add(Activation(binary_tanh_op))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, use_bias=False))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "\n",
    "# Train\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss=squared_hinge, optimizer=adam, metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "model.fit(\n",
    "    X_train, y_train, batch_size=128, epochs=100, validation_data=(X_test,y_test), verbose=1 )\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet Template 2017 data/LOSO/USCHAD.npz\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_1 (Conv1D)            (None, 500, 64)           3904      \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_2 (Conv1D)            (None, 500, 64)           41024     \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 500, 64)           256       \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 500, 64)           0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 32000)             0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 12)                384000    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 12)                48        \n",
      "=================================================================\n",
      "Total params: 429,488\n",
      "Trainable params: 429,208\n",
      "Non-trainable params: 280\n",
      "_________________________________________________________________\n",
      "Train on 8931 samples, validate on 893 samples\n",
      "Epoch 1/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9239 - acc: 0.3538 - val_loss: 0.9174 - val_acc: 0.4087\n",
      "Epoch 2/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9180 - acc: 0.4250 - val_loss: 0.9171 - val_acc: 0.4289\n",
      "Epoch 3/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9173 - acc: 0.4928 - val_loss: 0.9168 - val_acc: 0.4726\n",
      "Epoch 4/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9171 - acc: 0.5426 - val_loss: 0.9168 - val_acc: 0.4916\n",
      "Epoch 5/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9173 - acc: 0.5869 - val_loss: 0.9168 - val_acc: 0.4468\n",
      "Epoch 6/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9170 - acc: 0.6145 - val_loss: 0.9168 - val_acc: 0.5510\n",
      "Epoch 7/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9168 - acc: 0.6369 - val_loss: 0.9172 - val_acc: 0.5263\n",
      "Epoch 8/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.6545 - val_loss: 0.9170 - val_acc: 0.6741\n",
      "Epoch 9/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.6691 - val_loss: 0.9168 - val_acc: 0.4961\n",
      "Epoch 10/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.6772 - val_loss: 0.9169 - val_acc: 0.6181\n",
      "Epoch 11/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.6834 - val_loss: 0.9169 - val_acc: 0.4916\n",
      "Epoch 12/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.6827 - val_loss: 0.9171 - val_acc: 0.5655\n",
      "Epoch 13/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7007 - val_loss: 0.9167 - val_acc: 0.6876\n",
      "Epoch 14/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7012 - val_loss: 0.9169 - val_acc: 0.5901\n",
      "Epoch 15/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7027 - val_loss: 0.9170 - val_acc: 0.6025\n",
      "Epoch 16/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7028 - val_loss: 0.9171 - val_acc: 0.6047\n",
      "Epoch 17/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7003 - val_loss: 0.9169 - val_acc: 0.6081\n",
      "Epoch 18/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7076 - val_loss: 0.9170 - val_acc: 0.6058\n",
      "Epoch 19/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7214 - val_loss: 0.9170 - val_acc: 0.6394\n",
      "Epoch 20/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7163 - val_loss: 0.9167 - val_acc: 0.6988\n",
      "Epoch 21/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7154 - val_loss: 0.9168 - val_acc: 0.6495\n",
      "Epoch 22/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7287 - val_loss: 0.9167 - val_acc: 0.7324\n",
      "Epoch 23/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7183 - val_loss: 0.9175 - val_acc: 0.6125\n",
      "Epoch 24/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7243 - val_loss: 0.9169 - val_acc: 0.6226\n",
      "Epoch 25/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7351 - val_loss: 0.9171 - val_acc: 0.6249\n",
      "Epoch 26/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7414 - val_loss: 0.9167 - val_acc: 0.7346\n",
      "Epoch 27/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7129 - val_loss: 0.9169 - val_acc: 0.5957\n",
      "Epoch 28/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7083 - val_loss: 0.9168 - val_acc: 0.6965\n",
      "Epoch 29/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7183 - val_loss: 0.9169 - val_acc: 0.7525\n",
      "Epoch 30/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7289 - val_loss: 0.9171 - val_acc: 0.6820\n",
      "Epoch 31/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7365 - val_loss: 0.9169 - val_acc: 0.6764\n",
      "Epoch 32/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7344 - val_loss: 0.9169 - val_acc: 0.6797\n",
      "Epoch 33/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7342 - val_loss: 0.9167 - val_acc: 0.6999\n",
      "Epoch 34/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7258 - val_loss: 0.9167 - val_acc: 0.7469\n",
      "Epoch 35/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7300 - val_loss: 0.9167 - val_acc: 0.6013\n",
      "Epoch 36/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7327 - val_loss: 0.9167 - val_acc: 0.7447\n",
      "Epoch 37/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7270 - val_loss: 0.9169 - val_acc: 0.6506\n",
      "Epoch 38/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7336 - val_loss: 0.9168 - val_acc: 0.7716\n",
      "Epoch 39/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7542 - val_loss: 0.9167 - val_acc: 0.6204\n",
      "Epoch 40/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7448 - val_loss: 0.9167 - val_acc: 0.6965\n",
      "Epoch 41/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7356 - val_loss: 0.9167 - val_acc: 0.6551\n",
      "Epoch 42/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7429 - val_loss: 0.9168 - val_acc: 0.7032\n",
      "Epoch 43/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7461 - val_loss: 0.9168 - val_acc: 0.7055\n",
      "Epoch 44/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7515 - val_loss: 0.9169 - val_acc: 0.7077\n",
      "Epoch 45/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7379 - val_loss: 0.9168 - val_acc: 0.7525\n",
      "Epoch 46/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7450 - val_loss: 0.9170 - val_acc: 0.6013\n",
      "Epoch 47/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7456 - val_loss: 0.9167 - val_acc: 0.7984\n",
      "Epoch 48/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7383 - val_loss: 0.9168 - val_acc: 0.7088\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7246 - val_loss: 0.9167 - val_acc: 0.7077\n",
      "Epoch 50/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7345 - val_loss: 0.9168 - val_acc: 0.7380\n",
      "Epoch 51/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7340 - val_loss: 0.9172 - val_acc: 0.7010\n",
      "Epoch 52/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7151 - val_loss: 0.9173 - val_acc: 0.7077\n",
      "Epoch 53/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7375 - val_loss: 0.9167 - val_acc: 0.7346\n",
      "Epoch 54/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7372 - val_loss: 0.9168 - val_acc: 0.7548\n",
      "Epoch 55/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7508 - val_loss: 0.9172 - val_acc: 0.6114\n",
      "Epoch 56/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7439 - val_loss: 0.9167 - val_acc: 0.7223\n",
      "Epoch 57/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7447 - val_loss: 0.9167 - val_acc: 0.6876\n",
      "Epoch 58/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7403 - val_loss: 0.9168 - val_acc: 0.7604\n",
      "Epoch 59/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7186 - val_loss: 0.9168 - val_acc: 0.6831\n",
      "Epoch 60/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7265 - val_loss: 0.9167 - val_acc: 0.7503\n",
      "Epoch 61/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7456 - val_loss: 0.9168 - val_acc: 0.7256\n",
      "Epoch 62/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7429 - val_loss: 0.9167 - val_acc: 0.7671\n",
      "Epoch 63/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7491 - val_loss: 0.9167 - val_acc: 0.7279\n",
      "Epoch 64/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7441 - val_loss: 0.9167 - val_acc: 0.7458\n",
      "Epoch 65/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7274 - val_loss: 0.9177 - val_acc: 0.7077\n",
      "Epoch 66/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7428 - val_loss: 0.9170 - val_acc: 0.6797\n",
      "Epoch 67/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7428 - val_loss: 0.9167 - val_acc: 0.7592\n",
      "Epoch 68/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7476 - val_loss: 0.9170 - val_acc: 0.7413\n",
      "Epoch 69/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.6959 - val_loss: 0.9167 - val_acc: 0.7716\n",
      "Epoch 70/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7109 - val_loss: 0.9167 - val_acc: 0.7559\n",
      "Epoch 71/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7182 - val_loss: 0.9167 - val_acc: 0.6159\n",
      "Epoch 72/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7167 - val_loss: 0.9167 - val_acc: 0.7413\n",
      "Epoch 73/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7070 - val_loss: 0.9167 - val_acc: 0.7256\n",
      "Epoch 74/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7223 - val_loss: 0.9167 - val_acc: 0.6842\n",
      "Epoch 75/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7073 - val_loss: 0.9167 - val_acc: 0.5845\n",
      "Epoch 76/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7257 - val_loss: 0.9167 - val_acc: 0.7693\n",
      "Epoch 77/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7270 - val_loss: 0.9167 - val_acc: 0.7021\n",
      "Epoch 78/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7288 - val_loss: 0.9167 - val_acc: 0.7335\n",
      "Epoch 79/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7219 - val_loss: 0.9167 - val_acc: 0.7436\n",
      "Epoch 80/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7164 - val_loss: 0.9167 - val_acc: 0.6170\n",
      "Epoch 81/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7117 - val_loss: 0.9167 - val_acc: 0.7032\n",
      "Epoch 82/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7213 - val_loss: 0.9167 - val_acc: 0.6607\n",
      "Epoch 83/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7218 - val_loss: 0.9167 - val_acc: 0.7044\n",
      "Epoch 84/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7150 - val_loss: 0.9167 - val_acc: 0.7984\n",
      "Epoch 85/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7178 - val_loss: 0.9167 - val_acc: 0.7637\n",
      "Epoch 86/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7196 - val_loss: 0.9167 - val_acc: 0.7805\n",
      "Epoch 87/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7296 - val_loss: 0.9167 - val_acc: 0.6797\n",
      "Epoch 88/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7252 - val_loss: 0.9167 - val_acc: 0.7469\n",
      "Epoch 89/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7317 - val_loss: 0.9167 - val_acc: 0.7559\n",
      "Epoch 90/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7206 - val_loss: 0.9167 - val_acc: 0.8040\n",
      "Epoch 91/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7403 - val_loss: 0.9168 - val_acc: 0.6461\n",
      "Epoch 92/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7361 - val_loss: 0.9167 - val_acc: 0.7884\n",
      "Epoch 93/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7321 - val_loss: 0.9167 - val_acc: 0.7637\n",
      "Epoch 94/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7426 - val_loss: 0.9167 - val_acc: 0.7290\n",
      "Epoch 95/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7447 - val_loss: 0.9167 - val_acc: 0.7570\n",
      "Epoch 96/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7417 - val_loss: 0.9167 - val_acc: 0.7480\n",
      "Epoch 97/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7489 - val_loss: 0.9167 - val_acc: 0.7268\n",
      "Epoch 98/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7469 - val_loss: 0.9167 - val_acc: 0.7492\n",
      "Epoch 99/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7529 - val_loss: 0.9167 - val_acc: 0.7122\n",
      "Epoch 100/100\n",
      "8931/8931 [==============================] - 18s 2ms/step - loss: 0.9167 - acc: 0.7445 - val_loss: 0.9167 - val_acc: 0.7940\n",
      "893/893 [==============================] - 0s 529us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.9166673230297221, 0.7939529676336591]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input_file = 'data/LOSO/USCHAD.npz'\n",
    "\n",
    "tmp = np.load(data_input_file)\n",
    "X = tmp['X']\n",
    "y = tmp['y']\n",
    "folds = tmp['folds']\n",
    "\n",
    "n_class = y.shape[1]\n",
    "\n",
    "avg_acc = []\n",
    "avg_recall = []\n",
    "avg_f1 = []\n",
    "y = np.argmax(y, axis=1)\n",
    "\n",
    "print('ConvNet Template 2017 {}'.format(data_input_file))\n",
    "\n",
    "i = 0\n",
    "train_idx = folds[i][0]\n",
    "test_idx = folds[i][1]\n",
    "\n",
    "X_train, y_train = X[train_idx], y[train_idx]\n",
    "X_test, y_test = X[test_idx], y[test_idx]\n",
    "X_train = X_train.squeeze()\n",
    "X_test = X_test.squeeze()\n",
    "y_train = to_categorical(y_train)\n",
    "y_test = to_categorical(y_test)\n",
    "\n",
    "# Create Model\n",
    "model = Sequential()\n",
    "\n",
    "model.add(\n",
    "    Conv1D(\n",
    "        kernel_size=10,\n",
    "        filters=64,\n",
    "        padding='same',\n",
    "        input_shape=(500,6)))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv1D(\n",
    "        kernel_size=10, filters=64, padding='same'))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(12, use_bias=False))\n",
    "model.add(BatchNormalization(momentum=0.1, epsilon=0.0001))\n",
    "\n",
    "# Train\n",
    "adam = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n",
    "model.compile(loss=squared_hinge, optimizer=adam, metrics=['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "model.fit(\n",
    "    X_train, y_train, batch_size=50, epochs=100, validation_data=(X_test,y_test))\n",
    "model.evaluate(X_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
